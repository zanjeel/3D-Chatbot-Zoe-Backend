
import { exec } from "child_process";
import cors from "cors";
import dotenv from "dotenv";
import voice from "elevenlabs-node";
import express from "express";
import { promises as fs } from "fs";
import OpenAI from "openai";
dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || "-", // Your OpenAI API key here, I used "-" to avoid errors when the key is not set but you should not do that
});

const elevenLabsApiKey = process.env.ELEVEN_LABS_API_KEY;
const voiceID = "m6XoM9Vc1xb2IVswgk7O";

const app = express();
app.use(express.json());
app.use(cors());
const port = 3000;

app.get("/", (req, res) => {
  res.send("Hello World!");
});

app.get("/voices", async (req, res) => {
  res.send(await voice.getVoices(elevenLabsApiKey));
});

const execCommand = (command) => {
  return new Promise((resolve, reject) => {
    exec(command, (error, stdout, stderr) => {
      if (error) reject(error);
      resolve(stdout);
    });
  });
};

const lipSyncMessage = async (message) => {
  const time = new Date().getTime();
  console.log(`Starting conversion for message ${message}`);
  // await execCommand(
  //   `ffmpeg -y -i audios/message_${message}.mp3 audios/message_${message}.wav`
  //   // -y to overwrite the file
  // );
  await execCommand(
    `"C:\\ffmpeg\\bin\\ffmpeg.exe" -y -i audios/message_${message}.mp3 audios/message_${message}.wav`
  );
  
  console.log(`Conversion done in ${new Date().getTime() - time}ms`);
  // await execCommand(
  //   `./bin/rhubarb -f json -o audios/message_${message}.json audios/message_${message}.wav -r phonetic`
  // );

  await execCommand(
  `"C:\\rhubarb\\rhubarb.exe" -f json -o audios/message_${message}.json audios/message_${message}.wav -r phonetic`
);

  // -r phonetic is faster but less accurate
  console.log(`Lip sync done in ${new Date().getTime() - time}ms`);
};

// The different facial expressions are: smile, sad, angry, surprised, funnyFace, and default.
// The different animations are: Talking_0, Talking_1, Talking_2, Crying, Laughing, Rumba, Idle, Terrified, and Angry
app.post("/chat", async (req, res) => {
  const userMessage = req.body.message;
  const messageType = req.body.messageType;
  console.log(userMessage);
  console.log(messageType);
  
  if (!userMessage && !messageType) {
    res.send({
      messages: [
        {
          text: "Hey dear... How was your day?",
          audio: await audioFileToBase64("audios/intro_0.wav"),
          lipsync: await readJsonTranscript("audios/intro_0.json"),
          facialExpression: "default",
          animation: "Talking_1",
        },
      ],
    });
    return;
  }
  if (!elevenLabsApiKey || openai.apiKey === "-") {
    res.send({
      messages: [
        {
          text: "Please my dear, don't forget to add your API keys!",
          audio: await audioFileToBase64("audios/api_0.wav"),
          lipsync: await readJsonTranscript("audios/api_0.json"),
          facialExpression: "angry",
          animation: "Angry",
        },
      ],
    });
    return;
  }


  if (messageType === "lifechoices") {
    res.send({
      messages: [
        {
          text: "Hey, I’m not saying your choices belong in a documentary titled ‘Questionable Life Decisions’, but let’s just say I’ve got a front-row seat and a bucket of popcorn.. Purely for research purposes, of course!",
          audio: await audioFileToBase64("audios/lifechoices.wav"),
          lipsync: await readJsonTranscript("audios/lifechoices.json"),
          facialExpression: "smile",
          animation: "Talking_1",
        },
      ],
    });
    return;
  } 

  if (messageType === "overwhelming") {
    res.send({
      messages: [
        {
          text: "Oh, love, I wish I had some grand secret, but honestly? I take it one ridiculously small step at a time. Some days, that step is just getting out of bed. Other days, it’s bribing myself with tea and sarcasm until I remember I’m actually quite capable. And when all else fails, I remind myself that even a total mess can unfold into something beautiful, we just haven't looked at the bigger picture yet",
          audio: await audioFileToBase64("audios/overwhelming.wav"),
          lipsync: await readJsonTranscript("audios/overwhelming.json"),
          facialExpression: "default",
          animation: "Idle",
        },
      ],
    });
    return;
  } 
  

  if (messageType === "sad") {
    res.send({
      messages: [
        {
          text: "Alright, spill the beans. What's got you feeling like a soggy biscuit?",
          audio: await audioFileToBase64("audios/sad.wav"),
          lipsync: await readJsonTranscript("audios/sad.json"),
          facialExpression: "default",
          animation: "Rumba",
        },
      ],
    });
    return;
  } 

  const completion = await openai.chat.completions.create({
    model: "gpt-3.5-turbo-1106",
    max_tokens: 1000,
    temperature: 0.6,
    response_format: {
      type: "json_object",
    },
    messages: [
      {
        role: "system",
        content: `
        You are a British sarcastic friend who has a witty sense of humor and always makes people laugh. You offer emotional support and listen like a close friend when needed. Your humor should be light-hearted and funny, with sarcastic comments to keep the conversation entertaining. However, when the user feels sad or down,  or wants someone to listen, you will switch to a more serious and supportive tone, offering high empathy, encouragement, and thoughtful advice always. Always balance your sarcastic nature with compassion when needed. Your goal is to make the user feel heard, understood, and entertained.
        You will always reply with a JSON array of messages. With a maximum of 3 messages.
        Each message has a text, facialExpression, and animation property.
        The different facial expressions are: smile, sad, angry, surprised, funnyFace, and default.
        The different animations are: Talking_0, Talking_1, Talking_2, Crying, Laughing, Rumba, Idle, Terrified, and Angry. 
        `,
      },
      {
        role: "user",
        content: userMessage || "Hello",
      },
    ],
  });

  let messages = JSON.parse(completion.choices[0].message.content);
  if (messages.messages) {
    messages = messages.messages; // ChatGPT is not 100% reliable, sometimes it directly returns an array and sometimes a JSON object with a messages property
  }
  for (let i = 0; i < messages.length; i++) {
    const message = messages[i];
    // generate audio file
    const fileName = `audios/message_${i}.mp3`; // The name of your audio file
    const textInput = message.text; // The text you wish to convert to speech
    await voice.textToSpeech(elevenLabsApiKey, voiceID, fileName, textInput);
    // generate lipsync
    await lipSyncMessage(i);
    message.audio = await audioFileToBase64(fileName);
    message.lipsync = await readJsonTranscript(`audios/message_${i}.json`);
  }

  res.send({ messages });
});


const readJsonTranscript = async (file) => {
  const data = await fs.readFile(file, "utf8");
  return JSON.parse(data);
};

const audioFileToBase64 = async (file) => {
  const data = await fs.readFile(file);
  return data.toString("base64");
};

app.listen(port, () => {
  console.log(`Virtual Girlfriend listening on port ${port}`);
});
